# Cost Estimation Feature

## Overview

The LinkedIn Research Pipeline now includes upfront cost estimation functionality that provides detailed cost breakdowns before processing begins. This helps users understand the financial impact of their processing tasks and make informed decisions.

## Features

### ðŸŽ¯ Accurate Cost Estimation
- **Real-time calculation** using litellm's `token_counter()` and `cost_per_token()` functions
- **Model-specific pricing** for Perplexity Sonar and OpenAI GPT-4o-mini
- **Smart task detection** - only estimates costs for profiles that need processing

### ðŸ“Š Detailed Breakdown
- **Total estimated cost** across all profiles
- **Per-provider breakdown** (Research vs Email Generation)
- **Per-profile breakdown** showing individual costs
- **Token usage estimates** for input and output tokens

### ðŸ’¡ Intelligent Processing
- **Skip completed tasks** - doesn't estimate costs for profiles that already have research or drafts
- **Respects token limits** - factors in your configured max tokens settings
- **Fallback estimation** - provides backup estimates if token counting fails

## How It Works

### Cost Calculation Model

#### Research (Perplexity Sonar)
- **Input tokens**: $1.00 per million tokens
- **Output tokens**: $1.00 per million tokens  
- **Request fee**: $5.00 per 1000 requests
- **Typical output ratio**: 3x input tokens

#### Email Generation (OpenAI GPT-4o-mini)
- **Input tokens**: $0.15 per million tokens
- **Output tokens**: $0.60 per million tokens
- **Request fee**: None
- **Typical output ratio**: 0.5x input tokens

### Processing Logic

1. **Profile Analysis**: Checks which profiles need research and/or email generation
2. **Token Estimation**: Uses actual prompts to count input tokens via litellm
3. **Output Estimation**: Applies typical ratios based on task type
4. **Cost Calculation**: Multiplies tokens by current pricing rates
5. **Aggregation**: Sums costs across all profiles and tasks

## User Interface

### Main Display
- **Total Estimated Cost**: Overall cost for the batch
- **Profiles to Process**: Number of profiles that need work
- **Average Cost per Profile**: Total cost divided by profile count

### Detailed Breakdown (Expandable)
- **Research Section**: Profiles needing research, requests, tokens, cost
- **Email Section**: Profiles needing emails, requests, tokens, cost
- **Per-Profile Table**: Individual cost breakdown for each profile

### Cost Alerts
- ðŸŸ¢ **Low Cost** (< $0.10): Green success message
- ðŸŸ¡ **Medium Cost** ($0.10 - $1.00): Blue info message
- ðŸŸ  **High Cost** (> $1.00): Orange warning message

## Technical Implementation

### Key Components

#### CostEstimator Class
```python
class CostEstimator:
    def estimate_tokens(profile, task_type) -> dict
    def estimate_profile_cost(profile, config) -> dict  
    def estimate_batch_cost(df, config) -> dict
```

#### Integration Points
- **Profile Section**: Displays before "Start Processing" button
- **Sidebar**: Real-time cost tracking during processing
- **Configuration**: Respects max tokens and other settings

### Error Handling
- **Fallback estimation** if token counting fails
- **Graceful degradation** with simplified estimates
- **Clear error messages** for debugging

## Example Output

```
ðŸ’° Cost Estimation
Total Estimated Cost: $0.0067
Profiles to Process: 3
Avg Cost per Profile: $0.0022

ðŸ“Š Detailed Cost Breakdown
Research (Perplexity):
â€¢ Profiles needing research: 1
â€¢ Total requests: 1  
â€¢ Estimated tokens: 2,680
â€¢ Total cost: $0.0065

Email Generation (OpenAI):
â€¢ Profiles needing emails: 2
â€¢ Total requests: 2
â€¢ Estimated tokens: 787
â€¢ Total cost: $0.0002
```

## Benefits

### For Users
- **Budget planning** - know costs before spending
- **Process optimization** - identify expensive profiles
- **Informed decisions** - proceed with confidence

### For Operations
- **Cost control** - prevent unexpected charges
- **Resource planning** - estimate processing time
- **Transparency** - clear cost attribution

## Accuracy

The cost estimation is typically accurate within **Â±10%** of actual costs, with variations due to:
- **Response length variability** in AI outputs
- **Prompt complexity differences** between profiles
- **API pricing changes** (estimates use current rates)

The system errs on the side of slightly **overestimating** costs to avoid surprises.

## Future Enhancements

- **Historical cost tracking** and trend analysis
- **Budget limits** with automatic stopping
- **Cost optimization suggestions** 
- **Multi-currency support**
- **Custom pricing models** for enterprise users 